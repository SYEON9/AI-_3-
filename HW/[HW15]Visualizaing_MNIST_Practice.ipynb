{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW15]Visualizaing MNIST Practice.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPZacuCYvhnnRbisHdVAC9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SYEON9/natural_language_3th/blob/main/HW/%5BHW15%5DVisualizaing_MNIST_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality Reduction\n",
        "\n",
        "인간은 고차원 공간을 이해할 수 없기 때문에 이해할 수 있는 저차원으로 변환하는 기술을 연구했다. 이것을 dimensionality reduction이라고 한다. 이것을 이번 실습에서 직접적으로 이해해보자. 이번 실습은 MNIST dataset을 활용하여 수행해보겠다.\n"
      ],
      "metadata": {
        "id": "bdtx9Ka-17th"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65NoFaXa1w2-"
      },
      "outputs": [],
      "source": [
        "#데이터 불러오기\n",
        "#사용할 데이터는 MNIST Dataset이다. \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', cache = False)     #openml에서 데이터셋 이름으로 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#독립변수와 종속변수로 나누기\n",
        "#astype(): 데이터 프레임의 모든 타입이 같을 때 한번에 변환하기\n",
        "x = mnist.data.astype('float32').to_numpy()\n",
        "y = mnist.target.astype('int64').to_numpy()"
      ],
      "metadata": {
        "id": "38nfBqVF2t51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "IrZLc3OI_1UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 하나를 선택하여 데이터 확인하기\n",
        "plt.figure(figsize = (5,5))\n",
        "idx = 5\n",
        "\n",
        "grid_data = x[idx].reshape(28,28)      #이미지가 28x28이므로 784차원의 벡터를 가진다. \n",
        "plt.imshow(grid_data, interpolation = 'none') \n",
        "plt.show()\n",
        "\n",
        "print('label : {}'.format(y[idx]))"
      ],
      "metadata": {
        "id": "ikEbHu9l3mYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()      #matplotlib의 전체 그림을 지움. \n",
        "plt.figure(figsize = (5,5))\n",
        "\n",
        "rand_img = np.random.rand(28,28)\n",
        "plt.imshow(rand_img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nu8AxjKr4Up1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LH8TrO_y5AeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lJuvYvy5HIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9nPzLbS45HfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization using PCA\n",
        "\n",
        "데이터가 가장 흩어져있는 축을 찾아 projection하여 차원의 개수를 줄이는 방법이다. 우리는 데이터의 분산이 큰 축을 찾는 것을 목표로 한다. PCA는 scikit-learn 패키지를 활용하자."
      ],
      "metadata": {
        "id": "2yg5kpqQ5Hpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#70000개의 총 데이터를 사용하기엔 데이터 개수가 너무 많으므로 15000개만 사용해보자. \n",
        "labels = y[:15000]\n",
        "data=x[:15000]\n",
        "\n",
        "print('the shape of sample data = ', data.shape)"
      ],
      "metadata": {
        "id": "23oVHHHz5LGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터의 개수가 매우 많으므로 정규화도 시켜주자.\n",
        "#z-score normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardized_data = StandardScaler().fit_transform(data)\n",
        "print(standardized_data)"
      ],
      "metadata": {
        "id": "7CQY-zAM_ZWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data  = standardized_data"
      ],
      "metadata": {
        "id": "vFkvFTXJAek5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JVRW96SDAm27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 PCA를 적용해보자.\n",
        "from sklearn import decomposition\n",
        "\n",
        "pca = decomposition.PCA()"
      ],
      "metadata": {
        "id": "1Hf-nEx0Aor0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#우리는 feature의 차원을 2차원으로 축소할 것이다. \n",
        "pca.n_components = 2\n",
        "pca_data = pca.fit_transform(sample_data)   #sample data에 pca 적용.\n",
        "\n",
        "#pca를 적용하여 만들어진 데이터를 살펴보자.\n",
        "print('shape of pca_reduced.shape = ', pca_data.shape)    #데이터의 차원이 2차원으로 감소한 것을 알 수 있다."
      ],
      "metadata": {
        "id": "e89cn5OqAw3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_data.T.shape"
      ],
      "metadata": {
        "id": "JRCadfxfBVCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "JycaPfKvBchm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.vstack((pca_data.T, labels)).shape"
      ],
      "metadata": {
        "id": "KHo8quc8c5mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA 시각화\n",
        "\n",
        "각 label마다 색을 부여하여 시각화해보자. "
      ],
      "metadata": {
        "id": "GcETVjDeBcvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#먼저 2차원에 label을 추가한다. \n",
        "pca_data = np.vstack((pca_data.T, labels)).T     #배열을 row로 결합."
      ],
      "metadata": {
        "id": "eEb06xM-BjU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "#배열을 데이터프레임으로 만들자.\n",
        "pca_df = pd.DataFrame(data=pca_data, columns = ('1st_principal','2nd_principal','label'))\n",
        "\n",
        "#시각화하기\n",
        "#FacetGrid(): 다양한 범주형 값을 가지는 데이터를 시각화하는데 좋은 방법으로 행과 열 방향으로 서로 다른 조건을 적용하여 여러 개의 서브 플롯을 제작.\n",
        "sn.FacetGrid(pca_df, hue = 'label',size=6).map(plt.scatter, '1st_principal','2nd_principal')   #hue: 범례 추가\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nAYKj_YfdbZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j4bRu2lJfwe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U9UKFABTf91C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 직접 eigen vector를 구하고 데이터를 사영시켜 차원 축소를 진행시켜보자.\n",
        "\n"
      ],
      "metadata": {
        "id": "6NiGCBk0f-AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. eigen value와 eigen vector를 구하기 위해 공분산 행렬 구하자.\n",
        "covar_matrix = np.matmul(sample_data.T, sample_data)\n",
        "print(\"The shape of variance martix = \", covar_matrix.shape)"
      ],
      "metadata": {
        "id": "9XfW6VoIgE93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data.mean()"
      ],
      "metadata": {
        "id": "qKdYNze1gfYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.공분산 행렬을 이용해 scipy 패키지 안의 eigh 함수를 통해 eigen value와 eigen vector를 구하자\n",
        "#2D로 차원을 축소할 것이므로 가장 큰 두개의 값을 선정해서 구하자\n",
        "from scipy.linalg import eigh\n",
        "\n",
        "values, vectors = eigh(covar_matrix, eigvals = (782,783))\n",
        "print(\"Shape of eigen vectors = \", vectors.shape)\n",
        "\n",
        "vectors = vectors.T\n",
        "print(\"Updated shape of eigen vectors = \",vectors.shape)"
      ],
      "metadata": {
        "id": "ZulnJOKLgj2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 이제 eigen vector를 축으로 데이터를 사영시키자\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "new_coordinates = np.matmul(vectors, sample_data.T)\n",
        "print(\" Resultant new data points' shape \", vectors.shape, \"x\", sample_data.T.shape,'=', new_coordinates.shape)"
      ],
      "metadata": {
        "id": "NCrvhkvwhUIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "TmUVmKT-h3MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 우리 데이터는 784차원에서 2차원으로 줄어들었다.\n",
        "#아까처럼 시각화해보자.\n",
        "import pandas as pd\n",
        "\n",
        "new_coordinates = np.vstack((new_coordinates, labels.reshape(1,-1))).T\n",
        "\n",
        "dataframe = pd.DataFrame(data= new_coordinates, columns = ('1st_principal','2nd_principal','label'))\n",
        "print(dataframe.head())"
      ],
      "metadata": {
        "id": "mKc97Nx_h_F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "sn.FacetGrid(dataframe, hue = 'label', size = 6).map(plt.scatter, '1st_principal','2nd_principal').add_legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ICMRbR2iwQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "168RjF4hjJOW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}