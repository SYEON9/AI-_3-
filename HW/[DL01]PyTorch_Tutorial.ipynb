{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW]PyTorch Tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpBcHZzcgkbPtKSvBRKxTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SYEON9/natural_language_3th/blob/main/HW/%5BDL01%5DPyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w5BcyUlbGWCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import Package\n",
        "\n",
        "필요한 package를 설치하고 import하자. \n",
        "GPU를 사용할 것이므로 torch.cuda.is_avialable()이 True가 나와야 한다. "
      ],
      "metadata": {
        "id": "yxvkJ7UfE2uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "bMdx1BwaFGP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc350d2-7f3a-49ca-de01-61194dea7a8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#나머지 패키지를 불러오자\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "np.set_printoptions(precision=3)   #numpy 객체가 표시되는 방식 결정\n",
        "np.set_printoptions(suppress = True)    #고정소수점 표기법 사용."
      ],
      "metadata": {
        "id": "j9LZqWXnFOGC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "riOCCwogWFpx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oGVNA2O3W2qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tensor operations\n",
        "\n",
        "텐서는 array나 matrix와 매우 유사한 특수 자료구조이다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타낸다. \n",
        "텐서는 NumPy의 ndarray와 매우 유사하지만 GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다. "
      ],
      "metadata": {
        "id": "J4tENnflW3g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "twtc15UaXTqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#텐서 초기화하기\n",
        "데이터로부터 직접 생성하기\n"
      ],
      "metadata": {
        "id": "r_nUSzU2hJKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1,2],[3,4]]\n",
        "x = torch.tensor(data)    #tensor 생성\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1RDI9fQhNkg",
        "outputId": "98c2342b-f3a0-4377-e6c6-fe23501db163"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy array로부터 생성하기\n"
      ],
      "metadata": {
        "id": "67K_eJgWhfIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x = torch.tensor(np_array)   #ndarray를 torch.tensor로 변환가능.\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvpF0PLyhiDN",
        "outputId": "5b44e5b0-8d2d-439e-fc9a-f7913ec71aaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor에서 Numpy array로 변환하기\n"
      ],
      "metadata": {
        "id": "bnAdymoohwgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw5-peLah2jX",
        "outputId": "2afae1d7-0e99-49ac-e8ed-509f8bb9fdf7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다른 텐서와 같은 모양의 텐서 초기화하기"
      ],
      "metadata": {
        "id": "ChyORFSth7yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x)    #x_data의 속성을 유지한다. 1로 채워진 텐서를 x 크기로 반환한다. \n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")    #x의 원소가 int형이므로 int형으로 만듬.\n",
        "\n",
        "x_rand = torch.rand_like(x, dtype = torch.float)   #x_data의 속성을 덮어씁니다. 0~1사이의 무작위 값이 채워진 x크기의 tensor를 반환한다. \n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0YQYMy2h-oR",
        "outputId": "d6b08ccc-c300-4277-e760-9861f2eb7d88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.6593, 0.9410],\n",
            "        [0.9785, 0.6666]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "crT6clRkjeFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "주어진 shape으로 초기화하기"
      ],
      "metadata": {
        "id": "Kf3ziA6Ujmuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (3, 4)                   #원소의 기본형은 float\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2nbPRp7jqdb",
        "outputId": "737cda5b-51ef-410c-80c8-da1383e2bd48"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.1940, 0.2303, 0.2951, 0.6549],\n",
            "        [0.5364, 0.9793, 0.4207, 0.8655],\n",
            "        [0.1990, 0.5442, 0.6833, 0.0841]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RddF1dJgkk8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#텐서의 속성\n",
        "\n",
        "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타낸다."
      ],
      "metadata": {
        "id": "vMkKYNcNklL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU7zule9j06q",
        "outputId": "4bc78445-1175-44db-bdb2-0ec2bff67d79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iWSGJhRNlA3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cpu에 할당되어 있는 tensor를 GPU에 옮길 수 있다."
      ],
      "metadata": {
        "id": "kT08iQMdlEr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzLi-Vn6lKBG",
        "outputId": "1b5b1d97-51d1-4825-9712-fb7ea78b1b9c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k-JWlQ80lTcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#텐서 연산\n",
        "numpy 식의 인덱싱과 슬라이싱"
      ],
      "metadata": {
        "id": "V3XxN87cpwme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3,4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UszfZy9Jp0jc",
        "outputId": "ca94b555-0e19-4ca1-b4a5-8dbfe7feb697"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서 합치기"
      ],
      "metadata": {
        "id": "301i9cF1qRKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=0)   #행을 기준으로 tensor 합치기\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h0lg4eUqF4b",
        "outputId": "c900a4a5-5d41-4876-a68f-d27c0d927d4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkH6WZ5nqZeW",
        "outputId": "f5d02560-d778-4732-e71b-3bb91c873bc7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "STnGrauyq4be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서 곱하기"
      ],
      "metadata": {
        "id": "Vb4RHKoxq58Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#요소별 곱(element - wise product)을 계산한다.\n",
        "print(f\"Tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "\n",
        "#다른 문법\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nj3NsDqq7Or",
        "outputId": "4fbf2606-6fc2-4c2e-ea76-520b7a4e033e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KW6uY774rOqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서간 matrix multiplication 진행하기\n"
      ],
      "metadata": {
        "id": "F2G-H4DrrVv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#두 텐서의 행렬 곱 구하기\n",
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "\n",
        "#다른 문법:직접 곱하기\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfDKdTb2rZMZ",
        "outputId": "a1f9ca7e-077d-4b43-890f-2cdd6282d8e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xadJgBVUronD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autograd\n",
        "\n",
        "PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있다. 이는 모든 node에 대한 미분값을 자동으로 계산해준다.\n",
        "input X, params W, 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 autograd를 이용해서 구해보자."
      ],
      "metadata": {
        "id": "Ms8g6-m7sBzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zp4XG82dsWtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#input 및 params 초기화"
      ],
      "metadata": {
        "id": "3withxzMsX5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5)     #input tensor\n",
        "y = torch.zeros(3)    #expected output\n",
        "w = torch.randn(5,3, requires_grad = True)   #rand()가 0~1사이의 값으로 변환되는 것과 달리 평균이 0인 평균 분포로 나타낸다. \n",
        "b = torch.randn(3, requires_grad = True)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(w)\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmraJmyGsdmk",
        "outputId": "02d4139a-ef26-4987-eb35-25cbc30286ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0.])\n",
            "tensor([[-1.7750,  0.1882, -0.1376],\n",
            "        [ 2.3293,  0.5629,  1.0354],\n",
            "        [ 0.5014,  0.9516, -0.0618],\n",
            "        [-0.1594,  0.1861,  0.6967],\n",
            "        [ 1.4305,  0.7148, -0.6754]], requires_grad=True)\n",
            "tensor([ 0.7050,  1.7429, -1.1013], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forward"
      ],
      "metadata": {
        "id": "kATvXlm7tZS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w) + b\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NprYLxZeswF1",
        "outputId": "b36de18a-31a2-4e6b-e80b-52d4f49468aa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.0318,  4.3465, -0.2441], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss Function\n",
        "Pytorch에서는 node를 크게 2가지의 방법으로 api를 활용해서 사용한다. \n",
        "1. torch.nn\n",
        "2. torch.nn.functional\n",
        "\n",
        "\n",
        "torch.nn은 사전에 node를 초기화 시켜두고, 해당 node에 텐서를 통과시켜 값을 받는 형태이다. 그러나 torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식이다. \n",
        "\n",
        "코딩 스타일에 맞춰 원하는 api를 선택해 사용하면 된다."
      ],
      "metadata": {
        "id": "8OusQkXptpbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "loss = loss_fn(z, y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY507EFjtiXR",
        "outputId": "8ab246ad-c689-4480-a735-198716cc34d5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.6723, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Szf5d_umUV",
        "outputId": "1069c93c-8f5d-4788-9f72-ac66f44422e2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.6723, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bLkS5KcYusoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0TKs-PH7uzrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Backward\n",
        "모델에서 배개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수를 계산해야 한다. 이런 도함수를 계산하기 위해, loss.backward()를 호출한 다음 w.grad와 b.grad에서 값을 가져온다. "
      ],
      "metadata": {
        "id": "2EHCrsThuz6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeQQ_8FjvCcj",
        "outputId": "3316f9ce-df04-42e6-88a9-bc597df20d8d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[0.3180, 0.3291, 0.1464],\n",
            "        [0.3180, 0.3291, 0.1464],\n",
            "        [0.3180, 0.3291, 0.1464],\n",
            "        [0.3180, 0.3291, 0.1464],\n",
            "        [0.3180, 0.3291, 0.1464]])\n",
            "tensor([0.3180, 0.3291, 0.1464])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SWL7WwJ7vIM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로, requires_grad = True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원한다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있따. 연산 코드를 torch.no_grad()블록으로 둘러싸서 미분 추적을 멈출 수 있다."
      ],
      "metadata": {
        "id": "oac-j4t9vJy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w) + b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kviVu9yAvfal",
        "outputId": "1e529664-e2f3-46ea-c6cb-9f14035b9df3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jLCCzQT8vqUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}