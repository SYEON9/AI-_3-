{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW12]Logistic Regression Practice.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMRDfNXdPo/eRq0TPgxKRG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SYEON9/natural_language_3th/blob/main/HW/%5BHW12%5DLogistic_Regression_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression은 주어진 데이터와 가장 잘 맞는 직선을 찾는 방법이다. 하지만 예측값이 연속적인 값을 갖지 않는다면 어떻게 해야할까??\n",
        "여러 class를 분류해야하는 문제를 해결하려면 logistic regression을 사용해야 한다. "
      ],
      "metadata": {
        "id": "GdegIr_GPQbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmTC6EmRPFVF"
      },
      "outputs": [],
      "source": [
        "#Logistic regression\n",
        "import sympy\n",
        "import numpy\n",
        "\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = sympy.Symbol('z', real=True)\n",
        "\n",
        "logistic = 1/(1+sympy.exp(-z))\n",
        "logistic"
      ],
      "metadata": {
        "id": "xnQMCK3wP3Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sympy.plotting.plot(logistic)"
      ],
      "metadata": {
        "id": "dX6JgJb7QFg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g6RCeBmiQK7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 데이터를 직접 만들어서 실습해보자.\n",
        "#synthetic data(합성 데이터)\n",
        "x_data = numpy.linspace(-5,5,100)\n",
        "w = 2\n",
        "b = 1\n",
        "numpy.random.seed(0)\n",
        "z_data = b + w*x_data + numpy.random.normal(size=len(x_data))\n",
        "y_data = 1/(1+numpy.exp(-z_data))\n",
        "\n",
        "pyplot.scatter(x_data, y_data, alpha=0.4)"
      ],
      "metadata": {
        "id": "zSdGmx1xQV-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 실제 class값을 정해주자.\n",
        "#0.5보다 크면 1으로 작으면 0으로 class를 부여한다.\n",
        "y_data = numpy.where(y_data >= 0.5, 1, 0)\n",
        "pyplot.scatter(x_data, y_data, alpha=0.4);"
      ],
      "metadata": {
        "id": "X_bkzYJFQ4Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최적의 가중치를 찾기 위해서는 cost function을 정의하고 loss를 최소화해야한다. \n",
        "#그런데 이 cost function은 linear regression과 달리 logistic regression은 더이상 convex하지 않다.\n",
        "#이것은 sigmoid function 때문인데 실습으로 직접 확인해보자. \n",
        "\n",
        "badloss = (2 - 1/(1 + sympy.exp(-z)))**2 + \\\n",
        "          (-1 - 1/(1 + sympy.exp(-20*z)))**2 + \\\n",
        "          (5 - 1/(1 + sympy.exp(-5*z)))**2 \n",
        "badloss\n"
      ],
      "metadata": {
        "id": "HcNjdC1CRUT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sympy.plotting.plot(badloss, xlim = (-1,1));"
      ],
      "metadata": {
        "id": "zs4wNrctWmkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gradient descent 방법으로 위 cost function의 최솟값을 구하게 되면 중간에 기울기가 0인 지점에서 멈춘다.\n",
        "#즉, cost가 가장 작은 값에 도달하지 못하고 local minumum에 도달하게 된다. \n",
        "#그러므로 가중치에 대한 편미분으로 값을 각각 구해보도록 하겠다.\n",
        "\n",
        "Iprime = logistic.diff(z)\n",
        "Iprime"
      ],
      "metadata": {
        "id": "0uyHCX4CW9Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, y = sympy.symbols('a y', real = True)"
      ],
      "metadata": {
        "id": "bxJxBkpqXlzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dLda = (y - a)/a/(1-a)                  ##?????? 왜 (y-a)/(a*(1-a))가 아니지?\n",
        "dLda"
      ],
      "metadata": {
        "id": "yR1sXmhlX76l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = sympy.integrate(dLda, a)\n",
        "L"
      ],
      "metadata": {
        "id": "VuY5JmrkYBah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = -y*sympy.log(a) + (y-1)*sympy.log(1-a)\n",
        "L"
      ],
      "metadata": {
        "id": "BqMIU36MYt79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y=1인 경우의 cost값\n",
        "sympy.plotting.plot(-sympy.log(a), xlim = (0,1));"
      ],
      "metadata": {
        "id": "hf3-KAGaY87i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y=0인 경우의 cost값\n",
        "sympy.plotting.plot(-sympy.log(1-a), xlim = (0,1));"
      ],
      "metadata": {
        "id": "I-FFK13mZE4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sVWhwpMHZUFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JAn8UXNLZn2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 전체적인 과정을 따라가보면서 알아보자.\n",
        "logistic"
      ],
      "metadata": {
        "id": "O8kXcFwvZn9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b, x, y = sympy.symbols('w b x y')\n",
        "logistic = 1/(1 + sympy.exp(-w*x -b))\n",
        "\n",
        "Loss = -y*sympy.log(logistic) - (1-y)*sympy.log(1-logistic)\n",
        "Loss"
      ],
      "metadata": {
        "id": "giLc0wvmZvM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가중치 구하기(==기울기 구하기 == cost function 미분하기)\n",
        "from autograd import numpy\n",
        "from autograd import grad"
      ],
      "metadata": {
        "id": "-hBdr6DuaA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function define\n",
        "\n",
        "def logistic(z):\n",
        "    '''The logistic function'''\n",
        "    return 1 / (1 + numpy.exp(-z))\n",
        "\n",
        "def logistic_model(params, x):\n",
        "    '''A prediction model based on the logistic function composed with wx+b\n",
        "    Arguments:\n",
        "      params: array(w,b) of model paramsters\n",
        "      x: array of x data\n",
        "    '''\n",
        "    w = params[0]\n",
        "    b = params[1]\n",
        "    z = w * x + b\n",
        "    y = logistic(z)\n",
        "    return y\n",
        "\n",
        "def log_loss(params, model, x, y):\n",
        "    '''The logistic loss function \n",
        "    Arguuments:\n",
        "      params: array(w, b) of model parameters\n",
        "      model: the Python function for the logistic model\n",
        "      x, y: arrays of input data to the model\n",
        "    '''\n",
        "    y_pred = model(params, x)\n",
        "    return -numpy.mean(y * numpy.log(y_pred) + (1-y) * numpy.log(1-y_pred))"
      ],
      "metadata": {
        "id": "rGlCT4J7aPHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic loss의 gradient를 계산한 값을 얻자!\n",
        "gradient = grad(log_loss)                      "
      ],
      "metadata": {
        "id": "AfIMZM1Na2oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(gradient)"
      ],
      "metadata": {
        "id": "aO6MzRHLblZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grad()는 변수 개수만큼 output을 만든다. \n",
        "#우리는 w,b라는 변수 2개가 있으므로 기울기값을 구해보자\n",
        "numpy.random.seed(10)\n",
        "params = numpy.random.rand(2)      #params를 임의 설정\n",
        "print(params)"
      ],
      "metadata": {
        "id": "yc2Nw4UAbpMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기울기값을 구하자\n",
        "gradient(params, logistic_model, x_data, y_data)"
      ],
      "metadata": {
        "id": "IfBiNUgdcBeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ViUgbf4NcOHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gradient descent를 진행할때 반복수를 전부 채우지 않아도 기울기값이 0에 가까워지면 더 이상 반복하지 않도록 설정하자.\n",
        "max_iter = 5000\n",
        "i = 0\n",
        "descent = numpy.ones(len(params))\n",
        "\n",
        "while numpy.linalg.norm(descent) > 0.001 and i < max_iter:\n",
        "\n",
        "    descent = gradient(params, logistic_model, x_data, y_data)\n",
        "    params = params - descent * 0.01\n",
        "    i += 1\n",
        "\n",
        "print('Optimized value of w is {} vs. true value:2'.format(params[0]))\n",
        "print('Optimized value of b is {} vs. true value 1:'.format(params[1]))\n",
        "print('Exited after {} iterations'.format(i))\n",
        "\n",
        "pyplot.scatter(x_data, y_data, alpha = 0.4)\n",
        "pyplot.plot(x_data, logistic_model(params, x_data), '-r');"
      ],
      "metadata": {
        "id": "-ScIxudBcbFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class로 나눠보자.\n",
        "def decision_boundary(y):\n",
        "    return 1 if y>=0.5 else 0"
      ],
      "metadata": {
        "id": "_qtxfeSidYSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_boundary = numpy.vectorize(decision_boundary)"
      ],
      "metadata": {
        "id": "8EfFZvxsenxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(predictions):\n",
        "    '''\n",
        "    Argument:\n",
        "    predictions, an array of values between 0 and 1\n",
        "    \n",
        "    Returns: \n",
        "    classified, an array of 0 and 1 values'''\n",
        "\n",
        "    return decision_boundary(predictions).flatten()\n",
        "\n",
        "pyplot.scatter(x_data, y_data, alpha=0.4,\n",
        "               label='true value')\n",
        "pyplot.scatter(x_data, classify(logistic_model(params, x_data)), alpha=0.4, \n",
        "               label='prediciton')\n",
        "\n",
        "pyplot.legend();"
      ],
      "metadata": {
        "id": "ZC1ae0rZeuEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y44hE4yffWjh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}